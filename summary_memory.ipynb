{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv \n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"SummaryMemory\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI \n",
    "model = ChatOpenAI(model = \"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_15412\\223644811.py:4: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationSummaryMemory(llm = model, return_messages=True)\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.memory import ChatMessageHistory \n",
    "\n",
    "memory = ConversationSummaryMemory(llm = model, return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context(\n",
    "    {\"input\": \"John and Jake working on Machine Learning project\"},\n",
    "    {\"output\": \"Thats awesome! Whats the topic of project ?\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='The human mentions John and Jake working on a Machine Learning project. The AI responds positively, asking about the topic of the project.', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The human mentions John and Jake working on a Machine Learning project. The AI responds positively, asking about the topic of the project.\n"
     ]
    }
   ],
   "source": [
    "print(summary[\"history\"][0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context(\n",
    "    {\"input\": \"Machine learning project is focused on Healthcare\"},\n",
    "    {\"output\": \"Sounds exciting ! Are they building prediction model or classification\"}\n",
    ")\n",
    "memory.save_context(\n",
    "    {\"input\": \"Yes, they are working to predict disease of patient\"},\n",
    "    {\"output\": \"Awesome, Sounds very fascinating !\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The human mentions John and Jake working on a Machine Learning project focused on Healthcare. The AI responds positively, asking if they are building a prediction model or classification system. The human confirms they are working to predict diseases of patients. The AI finds it fascinating.\n"
     ]
    }
   ],
   "source": [
    "print(summary[\"history\"][0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InMemoryChatMessageHistory(messages=[HumanMessage(content='John and Jake working on Machine Learning project', additional_kwargs={}, response_metadata={}), AIMessage(content='Thats awesome! Whats the topic of project ?', additional_kwargs={}, response_metadata={}), HumanMessage(content='Machine learning project is focused on Healthcare', additional_kwargs={}, response_metadata={}), AIMessage(content='Sounds exciting ! Are they building prediction model or classification', additional_kwargs={}, response_metadata={}), HumanMessage(content='Yes, they are working to predict disease of patient', additional_kwargs={}, response_metadata={}), AIMessage(content='Awesome, Sounds very fascinating !', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.chat_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='John and Jake working on Machine Learning project', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Thats awesome! Whats the topic of project ?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Machine learning project is focused on Healthcare', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Sounds exciting ! Are they building prediction model or classification', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Yes, they are working to predict disease of patient', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Awesome, Sounds very fascinating !', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.chat_memory.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
