{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv \n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"ChatbotMemory\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "openai_embedding = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "model = ChatOpenAI(model = \"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "print(model.invoke(\"Hello\").content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4 \n",
    "from langchain import hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.history_aware_retriever import create_history_aware_retriever\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.prompts import ChatPromptTemplate \n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts import MessagesPlaceholder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(web_path=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",), bs_kwargs=dict(parse_only = bs4.SoupStrainer(class_ = (\"post-content\", \"post-title\", \"post-header\"))),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 200)\n",
    "splits = text_splitter.split_documents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(documents=splits, embedding=openai_embedding)\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x00000265BC3B7140>, search_kwargs={})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"You are an assistant for question answering tasks.\"\n",
    "    \"Use the following pieces of retrieved context to answer the question.\"\n",
    "    \"If you don't know the answer, Say that you don't know.\"\n",
    "    \"Use three sentences maximum and keep the answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answering_chain = create_stuff_documents_chain(model, chat_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = create_retrieval_chain(retriever, question_answering_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rag_chain.invoke({\"input\": \"What is MRKL ?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MRKL, short for “Modular Reasoning, Knowledge and Language”, is a neuro-symbolic architecture for autonomous agents. It contains a collection of “expert” modules and a general-purpose LLM that routes inquiries to the best suitable expert module. These modules can be neural or symbolic in nature.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_prompt = (\n",
    "    \"Given a chat history and the latest user question which might reference context in the chat history,\"\n",
    "    \"formulate a standalone question which can be understood without the chat history.\"\n",
    "    \"Do NOT answer the question, just reformulate it if needed and otherwise return it as is.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "contextualize_q_prompt  = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", retriever_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "\n",
    "\n",
    "     ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_aware_retriever = create_history_aware_retriever(model, retriever, contextualize_q_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt), \n",
    "        MessagesPlaceholder(\"chat_history\"), \n",
    "        (\"human\", \"{input}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(model, qa_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "question1 = \"What is Task Decomposition ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "message1 = rag_chain.invoke({\"input\": question1, \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task decomposition involves breaking down a complex task into smaller and simpler steps to make it more manageable. Techniques like Chain of Thought and Tree of Thoughts can help agents decompose hard tasks into multiple manageable tasks by instructing them to think step by step and explore multiple reasoning possibilities at each step. Task decomposition can be facilitated by using simple prompts, task-specific instructions, or human inputs to guide the agent in completing the overall task effectively.'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message1[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history.extend(\n",
    "    [\n",
    "        HumanMessage(content=question1),\n",
    "        AIMessage(content=message1[\"answer\"]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is Task Decomposition ?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Task decomposition involves breaking down a complex task into smaller and simpler steps to make it more manageable. Techniques like Chain of Thought and Tree of Thoughts can help agents decompose hard tasks into multiple manageable tasks by instructing them to think step by step and explore multiple reasoning possibilities at each step. Task decomposition can be facilitated by using simple prompts, task-specific instructions, or human inputs to guide the agent in completing the overall task effectively.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task decomposition can be done in common ways such as using simple prompts like \"Steps for XYZ\" or \"What are the subgoals for achieving XYZ?\" with Language Model (LLM) assistance, utilizing task-specific instructions tailored to the specific task at hand, or incorporating human inputs to guide the decomposition process effectively. These methods help break down complex tasks into smaller, more manageable steps, enabling agents to plan and execute tasks more efficiently.\n"
     ]
    }
   ],
   "source": [
    "second_question = \"What are the common ways of doing it ? \"\n",
    "message2 = rag_chain.invoke({\"input\": second_question, \"chat_history\": chat_history})\n",
    "print(message2[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory \n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory() \n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "converstational_rag_chain = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\", \n",
    "    history_messages_key=\"chat_history\", \n",
    "    output_messages_key=\"answer\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task decomposition involves breaking down a complex task into smaller and simpler steps to make it more manageable for an autonomous agent or AI system. Techniques like Chain of Thought (CoT) and Tree of Thoughts help in decomposing hard tasks into multiple manageable subtasks by guiding the model to \"think step by step\" or explore multiple reasoning possibilities at each step. This process allows the agent to plan ahead and execute tasks more effectively.'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converstational_rag_chain.invoke(\n",
    "    {\"input\": \"What is Task Decompostion ?\"}, \n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": \"abc123\"}\n",
    "    }\n",
    ")[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abc123': InMemoryChatMessageHistory(messages=[HumanMessage(content='What is Task Decompostion ?', additional_kwargs={}, response_metadata={}), AIMessage(content='Task decomposition involves breaking down a complex task into smaller and simpler steps to make it more manageable for an autonomous agent or AI system. Techniques like Chain of Thought (CoT) and Tree of Thoughts help in decomposing hard tasks into multiple manageable subtasks by guiding the model to \"think step by step\" or explore multiple reasoning possibilities at each step. This process allows the agent to plan ahead and execute tasks more effectively.', additional_kwargs={}, response_metadata={})])}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task decomposition can be achieved through various methods such as using Language Model (LLM) with simple prompting like \"Steps for XYZ\" or asking for subgoals, providing task-specific instructions like \"Write a story outline\" for a novel-writing task, or incorporating human inputs to guide the decomposition process. These approaches help in breaking down complex tasks into smaller components that can be easily tackled and executed by an autonomous agent or AI system.'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converstational_rag_chain.invoke(\n",
    "    {\"input\": \"What are the common ways of doing it ?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}}\n",
    ")[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user : What is Task Decompostion ?\n",
      "\n",
      "AI : Task decomposition involves breaking down a complex task into smaller and simpler steps to make it more manageable for an autonomous agent or AI system. Techniques like Chain of Thought (CoT) and Tree of Thoughts help in decomposing hard tasks into multiple manageable subtasks by guiding the model to \"think step by step\" or explore multiple reasoning possibilities at each step. This process allows the agent to plan ahead and execute tasks more effectively.\n",
      "\n",
      "user : What are the common ways of doing it ?\n",
      "\n",
      "AI : Task decomposition can be achieved through various methods such as using Language Model (LLM) with simple prompting like \"Steps for XYZ\" or asking for subgoals, providing task-specific instructions like \"Write a story outline\" for a novel-writing task, or incorporating human inputs to guide the decomposition process. These approaches help in breaking down complex tasks into smaller components that can be easily tackled and executed by an autonomous agent or AI system.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in store[\"abc123\"].messages:\n",
    "    if isinstance(i, AIMessage):\n",
    "        prefix = \"AI\"\n",
    "    else:\n",
    "        prefix = \"user\"\n",
    "    \n",
    "    print(f\"{prefix} : {i.content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A prompt technique like Chain of Thought (CoT) involves guiding a model to \"think step by step\" in order to decompose complex tasks into smaller and more manageable steps. This technique helps enhance model performance on difficult tasks by utilizing more test-time computation and shedding light on the model\\'s thinking process. CoT transforms big tasks into multiple manageable tasks, making it easier for the agent to plan and execute the necessary actions.'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converstational_rag_chain.invoke(\n",
    "    {\"input\": \"What is a prompt technique like step xyz?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abc123': InMemoryChatMessageHistory(messages=[HumanMessage(content='What is Task Decompostion ?', additional_kwargs={}, response_metadata={}), AIMessage(content='Task decomposition involves breaking down a complex task into smaller and simpler steps to make it more manageable for an autonomous agent or AI system. Techniques like Chain of Thought (CoT) and Tree of Thoughts help in decomposing hard tasks into multiple manageable subtasks by guiding the model to \"think step by step\" or explore multiple reasoning possibilities at each step. This process allows the agent to plan ahead and execute tasks more effectively.', additional_kwargs={}, response_metadata={}), HumanMessage(content='What are the common ways of doing it ?', additional_kwargs={}, response_metadata={}), AIMessage(content='Task decomposition can be achieved through various methods such as using Language Model (LLM) with simple prompting like \"Steps for XYZ\" or asking for subgoals, providing task-specific instructions like \"Write a story outline\" for a novel-writing task, or incorporating human inputs to guide the decomposition process. These approaches help in breaking down complex tasks into smaller components that can be easily tackled and executed by an autonomous agent or AI system.', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is a prompt technique like step xyz?', additional_kwargs={}, response_metadata={}), AIMessage(content='A prompt technique like Chain of Thought (CoT) involves guiding a model to \"think step by step\" in order to decompose complex tasks into smaller and more manageable steps. This technique helps enhance model performance on difficult tasks by utilizing more test-time computation and shedding light on the model\\'s thinking process. CoT transforms big tasks into multiple manageable tasks, making it easier for the agent to plan and execute the necessary actions.', additional_kwargs={}, response_metadata={})])}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What is Task Decompostion ?\n",
      "\n",
      "AI: Task decomposition involves breaking down a complex task into smaller and simpler steps to make it more manageable for an autonomous agent or AI system. Techniques like Chain of Thought (CoT) and Tree of Thoughts help in decomposing hard tasks into multiple manageable subtasks by guiding the model to \"think step by step\" or explore multiple reasoning possibilities at each step. This process allows the agent to plan ahead and execute tasks more effectively.\n",
      "\n",
      "User: What are the common ways of doing it ?\n",
      "\n",
      "AI: Task decomposition can be achieved through various methods such as using Language Model (LLM) with simple prompting like \"Steps for XYZ\" or asking for subgoals, providing task-specific instructions like \"Write a story outline\" for a novel-writing task, or incorporating human inputs to guide the decomposition process. These approaches help in breaking down complex tasks into smaller components that can be easily tackled and executed by an autonomous agent or AI system.\n",
      "\n",
      "User: What is a prompt technique like step xyz?\n",
      "\n",
      "AI: A prompt technique like Chain of Thought (CoT) involves guiding a model to \"think step by step\" in order to decompose complex tasks into smaller and more manageable steps. This technique helps enhance model performance on difficult tasks by utilizing more test-time computation and shedding light on the model's thinking process. CoT transforms big tasks into multiple manageable tasks, making it easier for the agent to plan and execute the necessary actions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for message in store[\"abc123\"].messages:\n",
    "    if isinstance(message, AIMessage):\n",
    "        prefix = \"AI\"\n",
    "    else:\n",
    "        prefix = \"User\"\n",
    "\n",
    "    print(f\"{prefix}: {message.content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
